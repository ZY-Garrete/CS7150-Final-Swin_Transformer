<!doctype html>
<html lang="en">

<head>
  <title>A Comparative Study of CNNs and Swin Transformers on Traffic Sign Classification</title>
  <meta property="og:title" content=Your Project Name" />
  <meta name="twitter:title" content="Your Project Name" />
  <meta name="description" content="Your project about your cool topic described right here." />
  <meta property="og:description" content="Your project about your cool topic described right here." />
  <meta name="twitter:description" content="Your project about your cool topic described right here." />
  <meta property="og:type" content="website" />
  <meta name="twitter:card" content="summary" />
  <meta name="viewport" content="width=device-width,initial-scale=1" />
  <!-- bootstrap for mobile-friendly layout -->
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.2/dist/css/bootstrap.min.css"
    integrity="sha384-xOolHFLEh07PJGoPkLv1IbcEPTNtaed2xpHsD9ESMhqIYd0nLMwNLD69Npy4HI+N" crossorigin="anonymous">
  <script src="https://cdn.jsdelivr.net/npm/jquery@3.5.1/dist/jquery.slim.min.js"
    integrity="sha384-DfXdz2htPH0lsSSs5nCTpuj/zy4C+OGpamoFVy38MVBnE+IbbVYUew+OrCXaRkfj"
    crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.2/dist/js/bootstrap.bundle.min.js"
    integrity="sha384-Fy6S3B9q64WdZWQUiU+q4/2Lc9npb8tCaSX9FK7E8HnRr0Jz8D6OP9dO5Vg3Q9ct"
    crossorigin="anonymous"></script>
  <link href="https://fonts.googleapis.com/css?family=Open+Sans:300,400,700" rel="stylesheet">
  <link href="style.css" rel="stylesheet">

</head>

<body class="nd-docs">
  <div class="nd-pageheader">
    <div class="container">
      <h1 class="lead">
        <nobr class="widenobr">A Comparative Study of CNNs and Swin Transformers on Traffic Sign Classification</nobr>
        <nobr class="widenobr">For CS 7150</nobr>
      </h1>
    </div>
  </div><!-- end nd-pageheader -->

  <div class="container">
    <div class="row">
      <div class="col justify-content-center text-center">
        <h2>An Analysis of "Swin Transformer: Hierarchical Vision Transformer using Shifted Windows"</h2>
        <p>This project investigates whether the Swin Transformer can outperform traditional CNNs like ResNet-50 in
          real-world image classification tasks. Using the GTSRB traffic sign dataset, we evaluate both models under the
          same training conditions to ensure a fair comparison. Our core question is whether vision transformers like
          Swin provide tangible benefits over conventional architectures. Additionally, we explore how the size of the
          attention window in Swin affects its performance, aiming to understand whether tuning this key parameter can
          further enhance its ability to recognize complex visual patterns.</p>
      </div>
    </div>
    <div class="row">
      <div class="col">

        <section id="analysis-section" style="display: flex; flex-direction: column; gap: 2rem; padding: 2rem;">

          <!-- Private Investigator -->
          <div style="border: 1px solid #ccc; border-radius: 12px; padding: 1rem;">
            <h3>Private Investigator</h3>
            <img src="images/ze_liu.jpg" alt="Ze Liu" style="width: 200px; border-radius: 8px; margin: 1rem 0;">
            <p><strong>Ze Liu</strong><br>
              Researcher at Microsoft Research Asia (MSRA)<br>
              Focus: Visual Representation Learning, Hierarchical Modeling</p>
            <p>Swin Transformer was proposed by a group of leading researchers at MSRA. Their goal was to design a
              general-purpose hierarchical vision transformer that can scale effectively across classification,
              detection, and segmentation tasks. The baseline CNN, ResNet, was also originally developed at MSRA.</p>
          </div>

          <!-- Diagrammer -->
          <!-- <div style="border: 1px solid #ccc; border-radius: 12px; padding: 1rem;">
            <h3>Diagrammer</h3>
            <img src="images/swin_vs_resnet.png" alt="Swin vs ResNet"
              style="width: 100%; border-radius: 8px; margin: 1rem 0;">
            <p>This diagram compares Swin Transformer’s hierarchical structure with the plain structure of ResNet. Swin
              uses shifted windows to compute local attention efficiently, while ResNet processes spatial data using
              convolutional kernels.</p>
          </div> -->

          <div class="card">
            <h3>Diagrammer</h3>


            <div class="carousel" style="overflow-x: auto; white-space: nowrap; padding-bottom: 1rem;">
              <img src="images/diagram1.png"
                style="width: 400px; display: inline-block; margin-right: 10px; border-radius: 8px;">
              <img src="images/diagram2.png"
                style="width: 400px; display: inline-block; margin-right: 10px; border-radius: 8px;">
              <img src="images/diagram3.png"
                style="width: 400px; display: inline-block; margin-right: 10px; border-radius: 8px;">
              <img src="images/diagram4.png"
                style="width: 400px; display: inline-block; margin-right: 10px; border-radius: 8px;">
              <img src="images/diagram5.png"
                style="width: 400px; display: inline-block; margin-right: 10px; border-radius: 8px;">
            </div>

            <p>These diagrams illustrate the key ideas of the Swin Transformer:
            <ul>
              <li><strong>Fig 1:</strong> Compares Swin Transformer’s hierarchical design with the flat architecture of
                ViT.</li>
              <li><strong>Fig 2:</strong> Shows how attention is computed in shifted windows to increase local
                connectivity.</li>
              <li><strong>Fig 3:</strong> Highlights how Swin processes images like traffic signs via patch partitioning
                and merging.</li>
              <li><strong>Fig 4:</strong>(a) The overall architecture of the Swin transformer (b) The two blocks of the
                Swin transformer.</li>
              <li><strong>Fig 5:</strong>The Swin Transformer architecture that yielded the best results after testing
                in this project.</li>
            </ul>
            </p>

            <p style="font-size: small; color: gray;">Figures from Liu et al., 2021, ICCV: "Swin Transformer:
              Hierarchical Vision Transformer using Shifted Windows".</p>
          </div>

          <!-- Reviewer -->
          <div style="border: 1px solid #ccc; border-radius: 12px; padding: 1rem;">
            <h3>Reviewer</h3>

            <p><strong>Review Score:</strong> <span style="font-weight: bold; font-size: 1.1rem;">7 — Accept</span></p>
            <p style="font-style: italic;">
              Swin Transformer, a unified backbone architecture that scales across vision tasks through hierarchical
              design
              and efficient windowed attention.
            </p>

            <h4 style="margin-top: 1rem;">Strengths:</h4>
            <ul style="padding-left: 1.2rem;">
              <li>
                Introduces an efficient <strong>shifted window mechanism</strong>, significantly reducing attention
                complexity while maintaining representation power.
              </li>
              <li>
                Strong empirical results across classification, detection, and segmentation benchmarks.
              </li>
              <li>
                Modular design easily extendable to future vision applications.
              </li>
            </ul>

            <h4 style="margin-top: 1rem;">Weaknesses:</h4>
            <ul style="padding-left: 1.2rem;">
              <li>Swin may not feel highly innovative compared to other vision architectures.</li>
              <li>Lacks theoretical justification for shift size or merging patterns.</li>
            </ul>
          </div>

          <!-- Experimenter -->
          <div style="border: 1px solid #ccc; border-radius: 12px; padding: 1rem;">
            <h3>Experimenter</h3>
            <img src="images/gtsrb_comparison.png" alt="GTSRB Results"
              style="width: 100%; border-radius: 8px; margin: 1rem 0;">
            <p>We implemented Swin-Tiny and ResNet-50 on the GTSRB dataset under the same conditions. The Swin
              Transformer outperformed ResNet in accuracy and convergence. We also investigated how changing the Swin
              window size affects model performance, with surprising insights on pattern sensitivity.</p>
          </div>

        </section>
        <h3>References</h3>

        <p><a name="bottou-1990">[1]</a>
          <a href="https://arxiv.org/abs/2103.14030" target="_blank">
            Liu, Z., Lin, Y., Cao, Y., Hu, H., Wei, Y., Zhang, Z., ... & Guo, B. (2021).
            <em>Swin Transformer: Hierarchical Vision Transformer using Shifted Windows</em>.
            In Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV), pp. 10012–10022.
          </a>
        </p>

        <h2>Team Members</h2>

        <p>Zefeng Zhao $ Zuyu Guo.</p>

        <!-- Acknowledgment -->
        <h2>Acknowledgment</h2>
        <p>
          We would like to express our sincere gratitude to
          <strong><a href="https://baulab.info/" target="_blank"
              style="text-decoration: none; color: #007acc;">Professor David Bau</a></strong>
          for his guidance throughout this course. His thoughtful lectures and insightful discussions helped us better
          understand modern deep learning models and inspired us to explore the capabilities of Swin Transformer in a
          real-world vision task.
        </p>



      </div><!--col-->
    </div><!--row -->
  </div> <!-- container -->

  <footer class="nd-pagefooter">
    <div class="row">
      <div class="col-6 col-md text-center">
        <a href="https://cs7150.baulab.info/">About CS 7150</a>
      </div>
    </div>
  </footer>

</body>
<script>
  $(document).on('click', '.clickselect', function (ev) {
    var range = document.createRange();
    range.selectNodeContents(this);
    var sel = window.getSelection();
    sel.removeAllRanges();
    sel.addRange(range);
  });
  // Google analytics below.
  window.dataLayer = window.dataLayer || [];
</script>

</html>